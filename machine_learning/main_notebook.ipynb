{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Install Required Libraries\n",
    "Note: If you've already installed the required libraries using requirements.txt, you can skip running this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run the following lines if you haven't installed the libraries yet.\n",
    "\n",
    "!pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Import Libraries and Load Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "from realesrgan import RealESRGAN\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import sys\n",
    "\n",
    "# Enable inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# For progress bars in Jupyter\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Ensure that the config.json is in the same directory as the notebook\n",
    "CONFIG_PATH = \"config.json\"\n",
    "\n",
    "# Load configuration\n",
    "try:\n",
    "    with open(CONFIG_PATH, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    print(\"Configuration loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Configuration file '{CONFIG_PATH}' not found. Please ensure it exists in the notebook directory.\")\n",
    "    sys.exit(1)\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error decoding JSON from '{CONFIG_PATH}': {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Extract configurations\n",
    "models_config = config.get(\"models\", {})\n",
    "stages_config = config.get(\"stages\", {})\n",
    "controlnet_config = config.get(\"controlnet\", {})\n",
    "image_savers_config = config.get(\"image_savers\", {})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Define Utility Functions for Image Preview and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_image(image, title=\"Image\"):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(image)\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def save_image(image, stage):\n",
    "    try:\n",
    "        # Create directories based on date if they don't exist\n",
    "        date_str = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        save_path_template = image_savers_config[stage][\"path\"]\n",
    "        save_path = save_path_template.format(date=date_str)\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        \n",
    "        # Generate filename with timestamp\n",
    "        timestamp = datetime.datetime.now().strftime(\"%H-%M-%S\")\n",
    "        extension = image_savers_config[stage][\"extension\"]\n",
    "        filename = f\"{stage}_{timestamp}.{extension}\"\n",
    "        full_path = os.path.join(save_path, filename)\n",
    "        \n",
    "        # Save image\n",
    "        image.save(full_path)\n",
    "        print(f\"Image saved at {full_path}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Missing configuration for image saver '{stage}': {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving image for stage '{stage}': {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Load ControlNet Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_controlnets(controlnet_paths):\n",
    "    controlnets = []\n",
    "    for path in controlnet_paths:\n",
    "        try:\n",
    "            cn = ControlNetModel.from_pretrained(path, torch_dtype=torch.float16)\n",
    "            controlnets.append(cn)\n",
    "            print(f\"Loaded ControlNet model from {path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading ControlNet model from {path}: {e}\")\n",
    "    return controlnets\n",
    "\n",
    "controlnet_model_paths = models_config.get(\"controlnet_model_paths\", [])\n",
    "if not controlnet_model_paths:\n",
    "    print(\"No ControlNet model paths found in configuration.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "controlnets = load_controlnets(controlnet_model_paths)\n",
    "if not controlnets:\n",
    "    print(\"Failed to load any ControlNet models. Exiting.\")\n",
    "    sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Load Stable Diffusion Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pipeline(base_model_path, controlnets):\n",
    "    try:\n",
    "        # Initialize the pipeline with ControlNet\n",
    "        pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
    "            base_model_path,\n",
    "            controlnet=controlnets,\n",
    "            torch_dtype=torch.float16,\n",
    "            safety_checker=None  # Disable safety checker if not needed\n",
    "        )\n",
    "        pipe = pipe.to(\"cuda\")\n",
    "        print(\"Loaded Stable Diffusion ControlNet Pipeline.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Stable Diffusion Pipeline: {e}\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Set scheduler\n",
    "    try:\n",
    "        pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "        print(\"Set scheduler to UniPCMultistepScheduler.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error setting scheduler: {e}\")\n",
    "    \n",
    "    return pipe\n",
    "\n",
    "base_model_path = models_config.get(\"base_model_path\", \"\")\n",
    "if not base_model_path:\n",
    "    print(\"Base model path not specified in configuration.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "pipe = load_pipeline(\n",
    "    base_model_path=base_model_path,\n",
    "    controlnets=controlnets\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Define Image Generation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(pipe, stage_config, control_images, seed):\n",
    "    prompt = stage_config.get(\"prompt\", \"\")\n",
    "    negative_prompt = stage_config.get(\"negative_prompt\", \"\")\n",
    "    steps = stage_config.get(\"steps\", 30)\n",
    "    sampler = stage_config.get(\"sampler\", \"dpmpp_2s_ancestral\")  # Placeholder: Implement sampler selection if needed\n",
    "    scheduler = stage_config.get(\"scheduler\", \"karras\")  # Placeholder: Implement scheduler selection if needed\n",
    "    width = stage_config.get(\"width\", 512)\n",
    "    height = stage_config.get(\"height\", 512)\n",
    "    cfg_scale = stage_config.get(\"cfg_scale\", 7.0)\n",
    "    \n",
    "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
    "    \n",
    "    # Prepare ControlNet inputs\n",
    "    # Assuming all ControlNet inputs use the same strength and no preprocessing\n",
    "    controlnet_inputs = []\n",
    "    for cn_model, control_image in zip(pipe.controlnet, control_images):\n",
    "        if control_image is not None:\n",
    "            controlnet_inputs.append({\n",
    "                \"controlnet\": cn_model,\n",
    "                \"control_image\": control_image,\n",
    "                \"strength\": controlnet_config.get(\"strength\", 1.0)\n",
    "            })\n",
    "        else:\n",
    "            print(\"Warning: One of the ControlNet control images is None. Skipping this ControlNet input.\")\n",
    "    \n",
    "    try:\n",
    "        with torch.autocast(\"cuda\"):\n",
    "            output = pipe(\n",
    "                prompt=prompt,\n",
    "                negative_prompt=negative_prompt,\n",
    "                num_inference_steps=steps,\n",
    "                guidance_scale=cfg_scale,\n",
    "                width=width,\n",
    "                height=height,\n",
    "                generator=generator,\n",
    "                controlnet=controlnet_inputs\n",
    "            )\n",
    "        image = output.images[0]\n",
    "        print(\"Image generation completed.\")\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(f\"Error during image generation: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Define Upscaling Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_image(image, stage_config):\n",
    "    scale = stage_config.get(\"scale\", 2.0)\n",
    "    denoise = stage_config.get(\"denoise\", 0.4)\n",
    "    tiles = stage_config.get(\"tiles\", 2)\n",
    "    model_path = models_config.get(\"realesrgan_model_path\", \"\")\n",
    "    \n",
    "    if not model_path:\n",
    "        print(\"Real-ESRGAN model path not specified in configuration. Skipping upscaling.\")\n",
    "        return image\n",
    "    \n",
    "    try:\n",
    "        # Initialize Real-ESRGAN\n",
    "        upsampler = RealESRGAN(device='cuda', scale=scale)\n",
    "        upsampler.load_weights(model_path)\n",
    "        print(\"Loaded Real-ESRGAN for upscaling.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Real-ESRGAN model from {model_path}: {e}\")\n",
    "        return image  # Return original image if upsampler fails\n",
    "    \n",
    "    try:\n",
    "        # Apply upscaling\n",
    "        upscaled_image = upsampler.predict(image, denoise=denoise, tile=tiles)\n",
    "        print(\"Upscaling completed.\")\n",
    "        return upscaled_image\n",
    "    except Exception as e:\n",
    "        print(f\"Error during upscaling: {e}\")\n",
    "        return image  # Return original image if upscaling fails\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Define AfterDetailer Function\n",
    "\n",
    "Note: The AfterDetailer step involves masking and refining specific areas. This implementation assumes that you have mask images or that you're using built-in masking capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def after_detailer(pipe, stage_config, control_images, seed, base_image):\n",
    "    prompt = stage_config.get(\"prompt\", \"\")\n",
    "    negative_prompt = stage_config.get(\"negative_prompt\", \"\")\n",
    "    mask_prompt = stage_config.get(\"mask_prompt\", \"\")  # Placeholder: Implement mask handling if needed\n",
    "    steps = stage_config.get(\"steps\", 30)\n",
    "    sampler = stage_config.get(\"sampler\", \"dpmpp_2s_ancestral\")  # Placeholder\n",
    "    scheduler = stage_config.get(\"scheduler\", \"karras\")  # Placeholder\n",
    "    denoise = stage_config.get(\"denoise\", 0.4)\n",
    "    mask_detection_area = stage_config.get(\"mask_detection_area\", True)\n",
    "    \n",
    "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
    "    \n",
    "    # Prepare ControlNet inputs\n",
    "    controlnet_inputs = []\n",
    "    for cn_model, control_image in zip(pipe.controlnet, control_images):\n",
    "        if control_image is not None:\n",
    "            controlnet_inputs.append({\n",
    "                \"controlnet\": cn_model,\n",
    "                \"control_image\": control_image,\n",
    "                \"strength\": controlnet_config.get(\"strength\", 1.0)\n",
    "            })\n",
    "        else:\n",
    "            print(\"Warning: One of the ControlNet control images is None. Skipping this ControlNet input.\")\n",
    "    \n",
    "    try:\n",
    "        with torch.autocast(\"cuda\"):\n",
    "            output = pipe(\n",
    "                prompt=prompt,\n",
    "                negative_prompt=negative_prompt,\n",
    "                num_inference_steps=steps,\n",
    "                guidance_scale=6.0,  # Adjusted CFG for refinement\n",
    "                generator=generator,\n",
    "                controlnet=controlnet_inputs,\n",
    "                image=base_image  # Assuming 'image' parameter is used for img2img-like refinement\n",
    "            )\n",
    "        refined_image = output.images[0]\n",
    "        print(\"AfterDetailer refinement completed.\")\n",
    "        return refined_image\n",
    "    except Exception as e:\n",
    "        print(f\"Error during AfterDetailer refinement: {e}\")\n",
    "        return base_image  # Return base image if refinement fails\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: Load ControlNet Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_control_images(stage):\n",
    "    # Define the paths to your control images\n",
    "    # Adjust these paths if your control images are stored elsewhere\n",
    "    control_image_paths = [\n",
    "        'control_image_1.png',\n",
    "        'control_image_2.png',\n",
    "        'control_image_3.png'\n",
    "    ]\n",
    "    \n",
    "    loaded_images = []\n",
    "    for path in control_image_paths:\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            loaded_images.append(img)\n",
    "            print(f\"Loaded control image: {path}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Control image '{path}' not found. Appending None.\")\n",
    "            loaded_images.append(None)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading control image '{path}': {e}. Appending None.\")\n",
    "            loaded_images.append(None)\n",
    "    return loaded_images\n",
    "\n",
    "# Load Control Images for TXT2IMG\n",
    "print(\"Loading ControlNet images for TXT2IMG...\")\n",
    "control_images_txt2img = load_control_images(\"txt2img\")\n",
    "\n",
    "# Load Control Images for Upscale (assuming same as txt2img)\n",
    "print(\"Loading ControlNet images for Upscale...\")\n",
    "control_images_upscale = control_images_txt2img.copy()\n",
    "\n",
    "# Load Control Images for AfterDetailer\n",
    "print(\"Loading ControlNet images for AfterDetailer...\")\n",
    "control_images_after_detailer = load_control_images(\"after_detailer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: Execute Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TXT2IMG Stage\n",
    "print(\"=== TXT2IMG Generation ===\")\n",
    "txt2img_stage = stages_config.get(\"txt2img\", {})\n",
    "if not txt2img_stage:\n",
    "    print(\"TXT2IMG stage configuration not found.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "base_image = generate_image(\n",
    "    pipe=pipe,\n",
    "    stage_config=txt2img_stage,\n",
    "    control_images=control_images_txt2img.copy(),\n",
    "    seed=txt2img_stage.get(\"seed\", 42)\n",
    ")\n",
    "\n",
    "if base_image:\n",
    "    preview_image(base_image, \"Base Image\")\n",
    "    save_image(base_image, \"txt2img\")\n",
    "else:\n",
    "    print(\"TXT2IMG generation failed. Exiting workflow.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Upscaling Stage\n",
    "print(\"\\n=== Upscaling ===\")\n",
    "upscale_stage = stages_config.get(\"upscale\", {})\n",
    "if not upscale_stage:\n",
    "    print(\"Upscale stage configuration not found.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "upscaled_image = upscale_image(\n",
    "    image=base_image,\n",
    "    stage_config=upscale_stage\n",
    ")\n",
    "\n",
    "if upscaled_image:\n",
    "    preview_image(upscaled_image, \"Upscaled Image\")\n",
    "    save_image(upscaled_image, \"upscale\")\n",
    "else:\n",
    "    print(\"Upscaling failed. Proceeding with base image.\")\n",
    "    upscaled_image = base_image\n",
    "\n",
    "# AfterDetailer Stage\n",
    "print(\"\\n=== AfterDetailer Refinement ===\")\n",
    "after_detailer_stage = stages_config.get(\"after_detailer\", {})\n",
    "if not after_detailer_stage:\n",
    "    print(\"AfterDetailer stage configuration not found.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "detailed_image = after_detailer(\n",
    "    pipe=pipe,\n",
    "    stage_config=after_detailer_stage,\n",
    "    control_images=control_images_after_detailer.copy(),\n",
    "    seed=after_detailer_stage.get(\"seed\", 42),\n",
    "    base_image=upscaled_image\n",
    ")\n",
    "\n",
    "if detailed_image:\n",
    "    preview_image(detailed_image, \"Detailed Image\")\n",
    "    save_image(detailed_image, \"after_detailer\")\n",
    "else:\n",
    "    print(\"AfterDetailer refinement failed.\")\n",
    "\n",
    "print(\"\\n=== Workflow Completed Successfully! ===\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
